{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#Originally Developed in FORTRAN by Dr. Mohammad Al-Hamdan  \n",
    "#USRA at NASA/MSFC\n",
    "#Converted into Python by Erica Burrows (2016)\n",
    "#Modified by Dr. Muhammad Barik (2017) for regional analysis.\n",
    "#Modified by Ching An Yang and Shane Coffield (2017)\n",
    "#Modified by Dr. Muhammad Barik (2018) \n",
    "#Modified by Anna Boser (2020)\n",
    "#Purpose: Extract MAIAC AOD Data from HDF Files based on EPA Regions\n",
    "'''\n",
    "\n",
    "# the LatLon file comes from https://portal.nccs.nasa.gov/datashare/maiac/DataRelease/NorthAmerica/\n",
    "\n",
    "#this script resample MODIS MAIAC data based defined grid values\n",
    "\n",
    "import os\n",
    "import gdal\n",
    "import numpy as n\n",
    "import time\n",
    "import pandas as pd\n",
    "import glob "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Unnamed: 0           X          Y     Id\n",
      "0               1 -123.494280  36.804508      1\n",
      "1               2 -123.482839  36.804508      2\n",
      "2               3 -123.471398  36.804508      3\n",
      "3               4 -123.459958  36.804508      4\n",
      "4               5 -123.448517  36.804508      5\n",
      "...           ...         ...        ...    ...\n",
      "57579       57580 -120.851483  38.995492  57580\n",
      "57580       57581 -120.840042  38.995492  57581\n",
      "57581       57582 -120.828602  38.995492  57582\n",
      "57582       57583 -120.817161  38.995492  57583\n",
      "57583       57584 -120.805720  38.995492  57584\n",
      "\n",
      "[57584 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# region = 'ACAL' #input('Enter selected area name: ')\n",
    "#region = 'Region1'\n",
    "#inc = float(raw_input('What is the Radius of Your Study Area in Decimal Degrees: '))\n",
    "# inc = 0.0117\n",
    "#band = raw_input('Which band would you like to use (0.47/0.55/0.66/avg)?: ')\n",
    "# band = '0.55'\n",
    "\n",
    "#USER: CHANGE/ADD YEARS AND PRODUCTS BASED ON YOUR PROJECT\n",
    "years = ['2017']\n",
    "products = ['DarkTarget Aqua V5.1 10km'] # ?????\n",
    "\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "df=pd.read_csv(\"C:\\\\Users\\\\aboser\\\\Documents\\\\GitHub\\\\PM_prediction\\\\Data\\\\fishnet\\\\fishnet_centroids_LatLon.csv\")\n",
    "\n",
    "#df=df.iloc[0:10000,:] #just for testing \n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-123.494279661017\n",
      "-120.80572033898301\n",
      "38.9954918032787\n",
      "36.804508196721294\n"
     ]
    }
   ],
   "source": [
    "lonmin = df.min(axis=None)[1]\n",
    "lonmax = df.max(axis=None)[1]\n",
    "latmax = df.max(axis=None)[2]\n",
    "latmin = df.min(axis=None)[2]\n",
    "\n",
    "print(lonmin)\n",
    "print(lonmax)\n",
    "print(latmax)\n",
    "print(latmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------\n",
      "Deleting all the existing files in the output folder.\n",
      "----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for product in products:\n",
    "    i=product.strip().split(' ')\n",
    "    alg = i[0]      #algorithm, DarkTarget or DeepBlue\n",
    "    sat = i[1]      #satellite, Aqua or Terra\n",
    "    vers = i[2]     #version, V5.1 or V6\n",
    "    res = i[3][:-2] #spatial resolution, 3 or 10\n",
    "\n",
    "    for year in years:\n",
    "        MAIAC_path = r'C:\\\\Users\\\\aboser\\\\Documents\\\\GitHub\\\\PM_prediction\\\\Data\\\\MAIAC' #MAIAC file folder\n",
    "        output_path=r'C:\\\\Users\\\\aboser\\\\Documents\\\\GitHub\\\\PM_prediction\\\\Data\\\\Variables\\\\AOD' #output folder \n",
    "        \n",
    "        print('----------------------------------------------------------')\n",
    "        print('Deleting all the existing files in the output folder.')\n",
    "        print('----------------------------------------------------------')\n",
    "        \n",
    "        existing_files = glob.glob('C:\\\\Users\\\\aboser\\\\Documents\\\\GitHub\\\\PM_prediction\\\\Data\\\\Processed\\\\AOD')\n",
    "        for ef in existing_files:\n",
    "            os.remove(ef)\n",
    "\n",
    "        #list and read MAIAC files \n",
    "        files = os.listdir(MAIAC_path) \n",
    "        files = [f for f in files if f[-3:]=='hdf']\n",
    "        count = 0\n",
    "        for f in files:\n",
    "            print('Reading MAIAC input files...')\n",
    "            count+=1\n",
    "            print ('Running file {} of {} ({})'.format(count, len(files), year))\n",
    "            dayfname = f[14:16]         #determining the day of each file\n",
    "            print ('DOY '+str(dayfname))\n",
    "            hdf_file = gdal.Open(MAIAC_path + f)    \n",
    "            print (f)\n",
    "            subDatasets = hdf_file.GetSubDatasets() #locating the keys of the subdatasets\n",
    "            latlon_path = r'C:\\\\Users\\\\aboser\\\\Documents\\\\GitHub\\\\PM_prediction\\\\Data\\\\MAIAC\\\\latlon\\\\MAIACLatlon.h08v05.hdf'\n",
    "            hdf_latlon_file =gdal.Open(latlon_path)\n",
    "            subDatasets_latlon = hdf_latlon_file.GetSubDatasets()\n",
    "                       \n",
    "            lat_key = 'HDF4_EOS:EOS_GRID:\"{}\":latlon:lat'.format(latlon_path)\n",
    "            lon_key = 'HDF4_EOS:EOS_GRID:\"{}\":latlon:lon'.format(latlon_path)\n",
    "            AOD_key = 'HDF4_EOS:EOS_GRID:\"{}\":grid1km:Optical_Depth_055'.format(MAIAC_path + f)\n",
    "                \n",
    "            lat = gdal.Open(lat_key).ReadAsArray().flatten()\n",
    "            lon = gdal.Open(lon_key).ReadAsArray().flatten()\n",
    "            AOD = gdal.Open(AOD_key).ReadAsArray().flatten()\n",
    "                        \n",
    "            AOD = AOD.astype('float')\n",
    "            AOD[AOD == -28672] = n.nan\n",
    "            print(len(AOD))\n",
    "            AOD = AOD * 0.001 #scale factor provided by HDF view app\n",
    "            conditions = (AOD>-9.9, lonmin<lon, lon<lonmax, latmin<lat, lat<latmax)\n",
    "            indices = n.where(n.logical_and.reduce(conditions))\n",
    "            #print(indices)\n",
    "            temp_cols = ['lon','lat','AOD']\n",
    "            #MAIAC_temp=[]\n",
    "            MAIAC_temp = pd.DataFrame(columns=temp_cols)\n",
    "            MAIAC_temp['lon'] = lon[indices]\n",
    "            MAIAC_temp['lat'] = lat[indices]\n",
    "            MAIAC_temp['AOD'] = AOD[indices]\n",
    "            print(len(MAIAC_temp['AOD']))\n",
    "            #print (MAIAC_temp)\n",
    "            MAIAC_temp=MAIAC_temp.round(6)\n",
    "            outputfile=output_path+'\\\\MAIAC_ACAL_{}_{}'.format(year,dayfname)+'.txt'\n",
    "            \n",
    "            resampled_AOD=[]\n",
    "            for i in range(len(df)):\n",
    "                #print(i)\n",
    "                con = ((df.iloc[i,1]-.01)<MAIAC_temp['lon'].values, MAIAC_temp['lon'].values <(df.iloc[i,1]+.01), (df.iloc[i,2]-.01)<MAIAC_temp['lat'].values , MAIAC_temp['lat'].values <(df.iloc[i,2]+.01))\n",
    "                ind= n.where(n.logical_and.reduce(con))\n",
    "                #print(ind)\n",
    "                if not n.any(ind):\n",
    "                    resampled_AOD.append(-999.0) \n",
    "                    #print('------------ NULL')\n",
    "                else:\n",
    "                    resampled_AOD.append(MAIAC_temp['AOD'].values[ind].mean())\n",
    "            df['AOD']=resampled_AOD  #pd.concat(df,resampled_AOD)\n",
    "            newDF=df.loc[:,'POINT_X':'AOD']\n",
    "            print ('Writing output ...')\n",
    "            if len(MAIAC_temp['AOD'])>0:\n",
    "              if os.path.exists(outputfile): # is the same day exists beacuse of multiple granuels form the same day\n",
    "                EF=pd.read_csv(outputfile, sep=' ', header=None)\n",
    "                \n",
    "                # where both of the values are not NAN\n",
    "                con = (newDF['AOD'] != -999.0, EF.iloc[:,-1] != -999.0 )\n",
    "                ind = n.where(n.logical_and.reduce(con))\n",
    "                newDF['AOD'].values[ind]=(newDF.iloc[:,-1].values[ind]+EF.iloc[:,-1].values[ind])/2\n",
    "                #where AOD from the previous granuale was NAN\n",
    "                con = (newDF['AOD'] == -999.0, EF.iloc[:,-1] != -999.0 )\n",
    "                ind = n.where(n.logical_and.reduce(con))\n",
    "                newDF['AOD'].values[ind]=EF.iloc[:,-1].values[ind]/2\n",
    "                \n",
    "                \n",
    "                with open(outputfile, 'w') as of:\n",
    "                    \n",
    "                    \n",
    "                    newDF.to_csv(of, header=None, index=None, sep=' ')\n",
    "                of.close()\n",
    "              else:\n",
    "                newDF.to_csv(outputfile, header=None, index=None, sep=' ')\n",
    "            else: #when the seelcted region have no data\n",
    "                 if os.path.exists(outputfile):\n",
    "                    print ('No need to write a nan file since already file with data exists')\n",
    "                 else:\n",
    "                    newDF.to_csv(outputfile, header=None, index=None, sep=' ')\n",
    "                 \n",
    "            #newDF.to_csv(r'/Volumes/F/CAARE_2017/CAARE_Barik/hindcasting/MAIAC_{}/MAIAC_ACAL_{}_{}'.format(year,year,dayfname)+'.txt', header=None, index=None, sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Total time taken to run:  3.1527342796325684\n"
     ]
    }
   ],
   "source": [
    "print ('Done! Total time taken to run: ', time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
